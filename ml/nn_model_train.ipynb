{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-21T04:32:56.484655300Z",
     "start_time": "2026-01-21T04:32:50.549009900Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from features import extract_handcrafted_features\n",
    "from nn_model import scamshield_model\n",
    "\n",
    "DATA_PATH = \"../data/messages.csv\"\n",
    "VEC_PATH = \"../artifacts/log_reg/vec.joblib\"\n",
    "OUTPUT_DIR = \"../artifacts/neural_net\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok = True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T04:32:56.527818200Z",
     "start_time": "2026-01-21T04:32:56.501311100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scipy_to_tf_sparse(X):\n",
    "    \"\"\"\n",
    "    Convert SciPy sparse matrix -> tf.sparse.SparseTensor\n",
    "    so Keras can accept sparse TF-IDF input.\n",
    "    \"\"\"\n",
    "    X = X.tocoo()\n",
    "    indices = np.stack([X.row, X.col], axis=1).astype(np.int64)\n",
    "    values = X.data.astype(np.float32)\n",
    "    shape = np.array(X.shape, dtype=np.int64)\n",
    "    st = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return tf.sparse.reorder(st)"
   ],
   "id": "f0fcc592434e9111",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T04:32:56.557649300Z",
     "start_time": "2026-01-21T04:32:56.527818200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # 1. loading the dataset\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "    y = df['label'].astype(int).to_numpy()\n",
    "\n",
    "    # Testing\n",
    "    # print(texts[5])\n",
    "    # print(y[5])\n",
    "\n",
    "    # 2. splitting\n",
    "    X_train_txt, X_test_txt, y_train, y_test = train_test_split(texts,\n",
    "                                                                y,\n",
    "                                                                test_size = 0.2,\n",
    "                                                                random_state = 42,\n",
    "                                                                stratify = y)\n",
    "\n",
    "    # 3. loading the fitted TF-IDF vectorizer\n",
    "    vec = load(VEC_PATH)\n",
    "    X_train_tfidf = vec.transform(X_train_txt)\n",
    "    X_test_tfidf = vec.transform(X_test_txt)\n",
    "\n",
    "    # 4. handcrafted features\n",
    "    X_train_hand = extract_handcrafted_features(X_train_txt)\n",
    "    X_test_hand = extract_handcrafted_features(X_test_txt)\n",
    "\n",
    "    # 5. Convert TF-IDF scipy sparse -> tf sparse\n",
    "    X_train_tfidf_tf = scipy_to_tf_sparse(X_train_tfidf)\n",
    "    X_test_tfidf_tf = scipy_to_tf_sparse(X_test_tfidf)\n",
    "\n",
    "    tfidf_dim = X_train_tfidf.shape[1]\n",
    "    hand_dim = X_train_hand.shape[1]\n",
    "    emb_dim = 64\n",
    "\n",
    "\n",
    "    # 6. building the model\n",
    "    model = scamshield_model(tfidf_dim = tfidf_dim,\n",
    "                             hand_dim = hand_dim,\n",
    "                             emb_dim = emb_dim)\n",
    "\n",
    "    # 7. compiling\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "        loss = {\n",
    "            \"prob\": \"binary_crossentropy\",\n",
    "            \"embedding\": \"mse\"\n",
    "        },\n",
    "        loss_weights = {\n",
    "            \"prob\": 1.0,\n",
    "            \"embedding\": 0.0\n",
    "        },\n",
    "        metrics = {\n",
    "            \"prob\":[\n",
    "                tf.keras.metrics.AUC(name = \"auc\"),\n",
    "                tf.keras.metrics.Precision(name = \"precision\"),\n",
    "                tf.keras.metrics.Recall(name = \"recall\")\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Dummy target for embedding (required because model has two outputs)\n",
    "    dummy_emb_train = np.zeros((len(y_train), emb_dim), dtype = np.float32)\n",
    "\n",
    "    callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_prob_auc\",\n",
    "        mode = \"max\",\n",
    "        patience = 3,\n",
    "        restore_best_weights = True\n",
    "    )]\n",
    "\n",
    "    # 8. fitting the model\n",
    "    history = model.fit(\n",
    "        x = {\"tfidf\": X_train_tfidf_tf,\n",
    "             \"handcrafted\": X_train_hand},\n",
    "        y = {\"prob\": y_train,\n",
    "             \"embedding\": dummy_emb_train},\n",
    "        validation_split = 0.2,\n",
    "        epochs = 15,\n",
    "        batch_size = 64,\n",
    "        callbacks = callbacks,\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # 9. predicting (prob + embedding)\n",
    "    preds = model.predict({\"tfidf\": X_test_tfidf_tf,\n",
    "                           \"handcrafted\": X_test_hand},\n",
    "                          verbose=0)\n",
    "    prob = preds[\"prob\"].reshape(-1)\n",
    "    emb = preds[\"embedding\"]\n",
    "\n",
    "    y_pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    # 10. evaluating\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, digits = 4)\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    print(\"ROC-AUC:\", auc)\n",
    "\n",
    "    # 11. saving the model\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"scamshield_nn_tf.keras\")\n",
    "    model.save(model_path)\n",
    "    np.save(os.path.join(OUTPUT_DIR, \"test_embeddings.npy\"), emb)\n",
    "\n",
    "    metrics_path = os.path.join(OUTPUT_DIR, \"metrics.json\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump({\"roc_auc\": float(auc)}, f, indent = 2)\n",
    "\n",
    "    print(\"\\nSaved:\")\n",
    "    print(\" - Model:\", model_path)\n",
    "    print(\" - Test embeddings:\", os.path.join(OUTPUT_DIR, \"test_embeddings.npy\"))\n",
    "    print(\" - Metrics:\", metrics_path)"
   ],
   "id": "b5d5d84ceefd88a2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T04:33:24.817373800Z",
     "start_time": "2026-01-21T04:32:56.563186200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "5de9ab9a823a223f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 52ms/step - embedding_loss: 0.6937 - loss: 0.4069 - prob_auc: 0.6377 - prob_loss: 0.4048 - prob_precision: 0.7424 - prob_recall: 0.3585 - val_embedding_loss: 1.0634 - val_loss: 0.1660 - val_prob_auc: 0.9153 - val_prob_loss: 0.1661 - val_prob_precision: 0.9302 - val_prob_recall: 0.7692\n",
      "Epoch 2/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 40ms/step - embedding_loss: 1.6064 - loss: 0.1400 - prob_auc: 0.9309 - prob_loss: 0.1394 - prob_precision: 0.9241 - prob_recall: 0.8317 - val_embedding_loss: 1.0254 - val_loss: 0.1132 - val_prob_auc: 0.9655 - val_prob_loss: 0.1131 - val_prob_precision: 0.8980 - val_prob_recall: 0.8462\n",
      "Epoch 3/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 38ms/step - embedding_loss: 1.2613 - loss: 0.0804 - prob_auc: 0.9794 - prob_loss: 0.0799 - prob_precision: 0.9377 - prob_recall: 0.8805 - val_embedding_loss: 1.0358 - val_loss: 0.0874 - val_prob_auc: 0.9779 - val_prob_loss: 0.0872 - val_prob_precision: 0.9010 - val_prob_recall: 0.8750\n",
      "Epoch 4/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 40ms/step - embedding_loss: 1.2941 - loss: 0.0611 - prob_auc: 0.9880 - prob_loss: 0.0610 - prob_precision: 0.9364 - prob_recall: 0.8976 - val_embedding_loss: 1.3167 - val_loss: 0.0852 - val_prob_auc: 0.9849 - val_prob_loss: 0.0850 - val_prob_precision: 0.9468 - val_prob_recall: 0.8558\n",
      "Epoch 5/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 39ms/step - embedding_loss: 1.3335 - loss: 0.0457 - prob_auc: 0.9933 - prob_loss: 0.0454 - prob_precision: 0.9457 - prob_recall: 0.9341 - val_embedding_loss: 1.1442 - val_loss: 0.0752 - val_prob_auc: 0.9862 - val_prob_loss: 0.0749 - val_prob_precision: 0.9474 - val_prob_recall: 0.8654\n",
      "Epoch 6/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 40ms/step - embedding_loss: 1.4030 - loss: 0.0307 - prob_auc: 0.9987 - prob_loss: 0.0308 - prob_precision: 0.9626 - prob_recall: 0.9415 - val_embedding_loss: 1.3560 - val_loss: 0.0694 - val_prob_auc: 0.9879 - val_prob_loss: 0.0691 - val_prob_precision: 0.9485 - val_prob_recall: 0.8846\n",
      "Epoch 7/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 38ms/step - embedding_loss: 1.6928 - loss: 0.0244 - prob_auc: 0.9992 - prob_loss: 0.0242 - prob_precision: 0.9799 - prob_recall: 0.9537 - val_embedding_loss: 1.4790 - val_loss: 0.0629 - val_prob_auc: 0.9881 - val_prob_loss: 0.0625 - val_prob_precision: 0.9216 - val_prob_recall: 0.9038\n",
      "Epoch 8/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 40ms/step - embedding_loss: 1.5251 - loss: 0.0229 - prob_auc: 0.9980 - prob_loss: 0.0227 - prob_precision: 0.9803 - prob_recall: 0.9732 - val_embedding_loss: 1.5545 - val_loss: 0.0642 - val_prob_auc: 0.9888 - val_prob_loss: 0.0638 - val_prob_precision: 0.9592 - val_prob_recall: 0.9038\n",
      "Epoch 9/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 35ms/step - embedding_loss: 2.0479 - loss: 0.0088 - prob_auc: 0.9999 - prob_loss: 0.0088 - prob_precision: 0.9950 - prob_recall: 0.9805 - val_embedding_loss: 1.2409 - val_loss: 0.1198 - val_prob_auc: 0.9849 - val_prob_loss: 0.1191 - val_prob_precision: 0.7937 - val_prob_recall: 0.9615\n",
      "Epoch 10/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 36ms/step - embedding_loss: 1.8661 - loss: 0.0194 - prob_auc: 0.9983 - prob_loss: 0.0192 - prob_precision: 0.9852 - prob_recall: 0.9732 - val_embedding_loss: 1.6553 - val_loss: 0.0815 - val_prob_auc: 0.9881 - val_prob_loss: 0.0811 - val_prob_precision: 0.9474 - val_prob_recall: 0.8654\n",
      "Epoch 11/15\n",
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 40ms/step - embedding_loss: 1.8008 - loss: 0.0128 - prob_auc: 0.9996 - prob_loss: 0.0127 - prob_precision: 0.9852 - prob_recall: 0.9756 - val_embedding_loss: 1.9094 - val_loss: 0.0816 - val_prob_auc: 0.9795 - val_prob_loss: 0.0810 - val_prob_precision: 0.9792 - val_prob_recall: 0.9038\n",
      "\n",
      "Confusion Matrix:\n",
      " [[903   1]\n",
      " [  6 122]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9934    0.9989    0.9961       904\n",
      "           1     0.9919    0.9531    0.9721       128\n",
      "\n",
      "    accuracy                         0.9932      1032\n",
      "   macro avg     0.9926    0.9760    0.9841      1032\n",
      "weighted avg     0.9932    0.9932    0.9932      1032\n",
      "\n",
      "ROC-AUC: 0.9922998478982301\n",
      "\n",
      "Saved:\n",
      " - Model: ../artifacts/neural_net\\scamshield_nn_tf.keras\n",
      " - Test embeddings: ../artifacts/neural_net\\test_embeddings.npy\n",
      " - Metrics: ../artifacts/neural_net\\metrics.json\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
